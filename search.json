[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data mining with {tidymodels}",
    "section": "",
    "text": "1 Preface\nThis is a book to convert example code on https://youngroklee-ml.github.io/data-mining-techniques/ into the {tidymodels} framework.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "index.html#tidymodels",
    "href": "index.html#tidymodels",
    "title": "Data mining with {tidymodels}",
    "section": "1.1 Tidymodels",
    "text": "1.1 Tidymodels\nThe tidymodels framework is a collection of packages to provide intuitive and unified interface for modeling and machine learning. To get more information, please see the following materials:\n\ntidymodels website: https://www.tidymodels.org\n“Tidy modeling with R” by Max Kuhn and Julia Silge: https://www.tmwr.org",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "index.html#model-engine-packages",
    "href": "index.html#model-engine-packages",
    "title": "Data mining with {tidymodels}",
    "section": "1.2 Model engine packages",
    "text": "1.2 Model engine packages\nEach modeling packages need to be separately installed to use it within the tidymodels framework. Example codes in this book require the following R packages.\n\nlibrary(glmnet)\nlibrary(mixOmics)\nlibrary(kknn)\nlibrary(klaR)\nlibrary(naivebayes)\nlibrary(LiblineaR)\nlibrary(kernlab)\nlibrary(ranger)\nlibrary(randomForest)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "ch02_regression.html",
    "href": "ch02_regression.html",
    "title": "2  Regression",
    "section": "",
    "text": "2.1 Examples 2.3 - 2.5, 2.7, 2.10 - 2.11",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "ch02_regression.html#examples-2.3---2.5-2.7-2.10---2.11",
    "href": "ch02_regression.html#examples-2.3---2.5-2.7-2.10---2.11",
    "title": "2  Regression",
    "section": "",
    "text": "2.1.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch2_reg1.csv\")\n\nRows: 10 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): ID, age, height, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(dat1)\n\n# A tibble: 10 × 4\n      ID   age height weight\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    21    170     60\n 2     2    47    167     65\n 3     3    36    173     67\n 4     4    15    165     54\n 5     5    54    168     73\n 6     6    25    177     71\n 7     7    32    169     68\n 8     8    18    172     62\n 9     9    43    171     66\n10    10    28    175     68\n\n\n\n\n2.1.2 Ex 2.3: Estimate coefficients\nUse {parsnip} package, a part of {tidymodels}, that provide a unified modeling interface.\nDefine a model type and engine.\n\nmodel &lt;- \n  linear_reg() |&gt;\n  set_engine(\"lm\") # \"lm\" is a default engine for `linear_reg()`\n\nEstimate the model by calling fit() function with formula and training data.\n\nmodel_fit &lt;- \n  model |&gt; \n  fit(weight ~ age + height, data = dat1)\n\nLet’s print estimation results.\n\nprint(model_fit)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ age + height, data = data)\n\nCoefficients:\n(Intercept)          age       height  \n  -108.1672       0.3291       0.9553  \n\n\nbroom::tidy() can extract coefficient statistics as data frame, including estimates and test statistics. Column estimate represents the coefficient estimates.\n\ntidy(model_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) -108.      42.1        -2.57 0.0371 \n2 age            0.329    0.0692      4.75 0.00208\n3 height         0.955    0.244       3.91 0.00579\n\n\n\n\n2.1.3 Ex 2.4: Estimate variance of error term\nbroom::glance() provides model-level statistics.\n\nglance(model_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.822         0.771  2.65      16.1 0.00239     2  -22.2  52.3  53.5\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nsigma is the estimate of standard deviation of the error term, so just square it to estimate the variance of the error term.\n\nglance(model_fit)[[\"sigma\"]]^2\n\n[1] 7.038464\n\n\n\n\n2.1.4 Ex 2.5: Test a model\nCall extract_fit_engine() when you need to explicitly use underlying lm object.\n\nextract_fit_engine(model_fit)\n\n\nCall:\nstats::lm(formula = weight ~ age + height, data = data)\n\nCoefficients:\n(Intercept)          age       height  \n  -108.1672       0.3291       0.9553  \n\n\nThis is important when a function that you call require the underlying engine’s object, not tidymodels framework’s wrapper class. anova() function to conduct ANOVA test is one of such functions that you need to pass lm object.\n\nmodel_fit |&gt; \n  extract_fit_engine() |&gt; \n  anova()\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \nage        1 119.299 119.299   16.95 0.004476 **\nheight     1 107.831 107.831   15.32 0.005793 **\nResiduals  7  49.269   7.038                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n2.1.5 Ex 2.7: Test each coefficient\nAs seen above, tidy() function returns data frame that contain test statistics.\n\ntidy(model_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) -108.      42.1        -2.57 0.0371 \n2 age            0.329    0.0692      4.75 0.00208\n3 height         0.955    0.244       3.91 0.00579\n\n\n\n\n2.1.6 Ex 2.10: Mean prediciton\nLet’s create a new data set as a tidyverse data frame tibble.\n\nnewdata &lt;- tibble(age = 40, height = 170)\n\nMake a mean prediction by calling predict() function, and append it to the data set as a column by calling bind_cols().\n\nnewdata |&gt; \n  bind_cols(predict(model_fit, new_data = newdata))\n\n# A tibble: 1 × 3\n    age height .pred\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1    40    170  67.4\n\n\nAlso, add 95% confidence interval by calling predict() function with argument type = \"conf_int\".\n\nnewdata |&gt; \n  bind_cols(predict(model_fit, new_data = newdata)) |&gt; \n  bind_cols(predict(model_fit, new_data = newdata, type = \"conf_int\"))\n\n# A tibble: 1 × 5\n    age height .pred .pred_lower .pred_upper\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1    40    170  67.4        65.0        69.8\n\n\n\n\n2.1.7 Ex 2.11 Prediction interval\nInstead of confidence interval, you can add prediction interval by passing argument type = \"pred_int\".\n\nnewdata |&gt; \n  bind_cols(predict(model_fit, new_data = newdata)) |&gt; \n  bind_cols(predict(model_fit, new_data = newdata, type = \"pred_int\"))\n\n# A tibble: 1 × 5\n    age height .pred .pred_lower .pred_upper\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1    40    170  67.4        60.7        74.1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "ch02_regression.html#examples-2.14-2.16",
    "href": "ch02_regression.html#examples-2.14-2.16",
    "title": "2  Regression",
    "section": "2.2 Examples 2.14, 2.16",
    "text": "2.2 Examples 2.14, 2.16\n\n2.2.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch2_coil.csv\")\n\nRows: 10 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): temp, thick, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.2.2 Ex 2.14: Indicator variable\n\n2.2.2.1 Set indicator variable\nDefine feature engineering steps with {recipes} package, a part of {tidymodels}.\nFirst, call recipe() to define input variables, output variable, and data.\n\nrec &lt;- \n  recipe(y ~ temp + thick, data = dat1)\n\nSee the recipe recognizes that there are one outcome variable and two predictor variables.\n\nrec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 2\n\n\nYou want to consider thick as a categorical variable by using factor() inside step_mutate() and create a dummy variable by adding step_dummy().\n\nrec &lt;- \n  rec |&gt; \n  step_mutate(thick = factor(thick, levels = c(6, 2))) |&gt; \n  step_dummy(thick)\n\nNow check that the updated recipe recognize thick as a dummy variable.\n\nrec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 2\n\n\n\n\n\n── Operations \n\n\n• Variable mutation for: factor(thick, levels = c(6, 2))\n\n\n• Dummy variables from: thick\n\n\nOf course, you can make write it as one pipeline\n\nrec &lt;- \n  recipe(y ~ temp + thick, data = dat1) |&gt; \n  step_mutate(thick = factor(thick, levels = c(6, 2))) |&gt; \n  step_dummy(thick)\n\nQuickly see what the output would look like. Here, prep() is a function to train feature engineering, and juice() is a result of applying the feature engineering to training data.\n\nrec |&gt; \n  prep() |&gt; \n  juice()\n\n# A tibble: 10 × 3\n    temp     y thick_X2\n   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1   540  52.5        1\n 2   660  50.2        1\n 3   610  51.3        1\n 4   710  49.1        1\n 5   570  50.8        0\n 6   700  48.7        0\n 7   560  51.2        0\n 8   600  50.8        0\n 9   680  49.3        0\n10   530  51.5        0\n\n\n\n\n2.2.2.2 Include feature engineering into a workflow\nLet’s start with defining model type and engine as we did in the first example above.\n\nmodel &lt;- \n  linear_reg() |&gt; \n  set_engine(\"lm\")\n\nNow, let’s define a “workflow” from {workflows} package, a part of {tidymodels}, to combine a recipe and a model.\n\nwflow &lt;- \n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(model) \n\nThe workflow recognizes that rec is a preprocessor before estimating a regression model.\n\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_mutate()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nNow, call fit() function by passing training data to estimate a regression model.\n\nlm_model &lt;- \n  wflow |&gt; \n  fit(dat1)\n\nSee the model estimation results.\n\nlm_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_mutate()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)         temp     thick_X2  \n   61.10797     -0.01768      0.80415  \n\n\nYou can still use broom::tidy() function to return coefficient-level statistics.\n\ntidy(lm_model)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  61.1      0.703       86.9  7.06e-12\n2 temp         -0.0177   0.00115    -15.4  1.18e- 6\n3 thick_X2      0.804    0.150        5.38 1.03e- 3\n\n\n\n\n\n2.2.3 Ex 2.16: Interaction\nYou can revise the workflow by updating recipe to include interaction term.\n\n2.2.3.1 Update recipe\nAdd step_interact() to existing recipe to add interaction term. Because a dummy variable will be used in this step, use starts_with(\"thick\") to capture dummy variable names, instead of using original variable name.\n\nrec_interaction &lt;-\n  rec |&gt; \n  step_interact(terms = ~ temp:starts_with(\"thick\"))\n\n\nrec_interaction\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 2\n\n\n\n\n\n── Operations \n\n\n• Variable mutation for: factor(thick, levels = c(6, 2))\n\n\n• Dummy variables from: thick\n\n\n• Interactions with: temp:starts_with(\"thick\")\n\n\nAgain, quickly check a resulting training data.\n\nrec_interaction |&gt; \n  prep() |&gt; \n  juice()\n\n# A tibble: 10 × 4\n    temp     y thick_X2 temp_x_thick_X2\n   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n 1   540  52.5        1             540\n 2   660  50.2        1             660\n 3   610  51.3        1             610\n 4   710  49.1        1             710\n 5   570  50.8        0               0\n 6   700  48.7        0               0\n 7   560  51.2        0               0\n 8   600  50.8        0               0\n 9   680  49.3        0               0\n10   530  51.5        0               0\n\n\n\n\n2.2.3.2 Update workflow\nUpdate workflow by calling update_recipe().\n\nwflow_interaction &lt;- \n  wflow |&gt; \n  update_recipe(rec_interaction)\n\n\nwflow_interaction\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_mutate()\n• step_dummy()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n2.2.3.3 Estimate a model with the new workflow\nCall fit() function with the new workflow.\n\nlm_model_interaction &lt;- \n  wflow_interaction |&gt; \n  fit(dat1)\n\nSee estimated coefficients.\n\ntidy(lm_model_interaction)\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic  p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     60.1       0.750       80.2  2.53e-10\n2 temp            -0.0161    0.00123    -13.1  1.23e- 5\n3 thick_X2         3.28      1.21         2.71 3.52e- 2\n4 temp_x_thick_X2 -0.00399   0.00194     -2.05 8.57e- 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "ch03_regularized_regression.html",
    "href": "ch03_regularized_regression.html",
    "title": "3  Regularized regression",
    "section": "",
    "text": "3.1 Examples 3.1 - 3.2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regularized regression</span>"
    ]
  },
  {
    "objectID": "ch03_regularized_regression.html#examples-3.1---3.2",
    "href": "ch03_regularized_regression.html#examples-3.1---3.2",
    "title": "3  Regularized regression",
    "section": "",
    "text": "3.1.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch3_dat1.csv\")\n\nRows: 7 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x1, x2, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNumber of objects\n\nN &lt;- nrow(dat1)\nN\n\n[1] 7\n\n\n\n\n3.1.2 Standardize input variables\nDefine a recipe to standardize each input variable\n\nrec &lt;- \n  recipe(y ~ x1 + x2, data = dat1) |&gt; \n  step_normalize(x1, x2)\n\n\n\n3.1.3 Ex 3.1: Lasso\n\n3.1.3.1 Basics\nRegularized regression model is still defined by linear_reg(), but with additional arguments penalty and mixture, where penalty is for the amount of regularization, while mixture is for proportion of L1 regularization. Set mixture = 1 to be Lasso. And let us set penalty = 0 to check a regression coefficient without regularization.\nDefault engine \"lm\" does not support regularized regression, so you should set a specific engine that support regularized regression. Let us use \"glmnet\" here.\n\nlasso_model &lt;- \n  linear_reg(penalty = 0, mixture = 1) |&gt; \n  set_engine(\"glmnet\")\n\nThis is translated into {glmnet} syntax like below:\n\nlasso_model |&gt; \n  translate()\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 0\n  mixture = 1\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    alpha = 1, family = \"gaussian\")\n\n\nDefine a workflow for Lasso regression.\n\nlasso_wflow &lt;- \n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(lasso_model)\n\nThen estimate the model.\n\nmodel_fit &lt;- \n  lasso_wflow |&gt; \n  fit(data = dat1)\n\n\ntidy(model_fit)\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\n# A tibble: 3 × 3\n  term        estimate penalty\n  &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 6.28e-17       0\n2 x1          2.01e+ 0       0\n3 x2          1.26e- 1       0\n\n\n\n\n3.1.3.2 Set regularization path\nPrevious result is slightly different from a result of typical linear regression.\n\nworkflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(linear_reg()) |&gt; \n  fit(data = dat1) |&gt; \n  tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 3.37e-18     0.172  1.96e-17 1      \n2 x1          2.02e+ 0     0.306  6.60e+ 0 0.00272\n3 x2          1.34e- 1     0.306  4.38e- 1 0.684  \n\n\nA region is that {glmnet} consumes additional parameter lambda to set a series of values called “regularization path”, and the model approximates between the closet path values. So, if you want to obtain more correct coefficient or prediction associated with a particular penalty amount, include the value to regularization path with glmnet-specific optional parameter path_values in set_engine(). See Technical aspects of the glmnet model\n\nregularization_path &lt;- c(3:0) / (2 * N - 1)\n\nlasso_model &lt;- \n  linear_reg(penalty = 0, mixture = 1) |&gt; \n  set_engine(\"glmnet\", path_values = regularization_path)\n\n\nlasso_model |&gt; \n  translate()\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 0\n  mixture = 1\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    lambda = regularization_path, alpha = 1, family = \"gaussian\")\n\n\nDefine a workflow for Lasso regression.\n\nlasso_wflow &lt;- \n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(lasso_model)\n\nmodel_fit &lt;- \n  lasso_wflow |&gt; \n  fit(data = dat1)\n\n\ntidy(model_fit)\n\n# A tibble: 3 × 3\n  term        estimate penalty\n  &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 6.35e-17       0\n2 x1          2.02e+ 0       0\n3 x2          1.33e- 1       0\n\n\nTo obtain coefficients for all four penalty amounts of interest in the regularization path, we can extract the glmnet object and apply specific function.\n\nmodel_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  extract_fit_engine() |&gt; \n  predict(type = \"coefficients\") |&gt; \n  round(4)\n\n3 x 4 sparse Matrix of class \"dgCMatrix\"\n                s0     s1     s2     s3\n(Intercept) 0.0000 0.0000 0.0000 0.0000\nx1          1.8771 1.9279 1.9743 2.0207\nx2          .      0.0409 0.0872 0.1335\n\n\n\n\n\n3.1.4 Ex 3.2: Ridge\nRidge is very similar to Lasso, except setting mixture = 0. Let us define the workflow for ridge regression.\n\nregularization_path &lt;- c(3:0) / (N - 1) * 2\n\nridge_model &lt;- \n  linear_reg(penalty = 0, mixture = 0) |&gt; \n  set_engine(\"glmnet\", path_values = regularization_path)\n\nridge_wflow &lt;- \n  workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(ridge_model)\n\n\nmodel_fit &lt;- \n  ridge_wflow |&gt; \n  fit(data = dat1)\n\nmodel_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  extract_fit_engine() |&gt; \n  predict(type = \"coefficients\") |&gt; \n  round(4)\n\n3 x 4 sparse Matrix of class \"dgCMatrix\"\n                s0     s1     s2     s3\n(Intercept) 0.0000 0.0000 0.0000 0.0000\nx1          1.1178 1.2687 1.5069 2.0194\nx2          0.5667 0.5477 0.4639 0.1345\n\n\nEven though obtaining coefficients is somewhat tedious because it requires extraction of underlying model objects, making a prediction from all the penalty amounts of interest is a little bit more convenient by using multi_predict() function. However, data preprocessing for new data needs to be separately done.\n\nridge_pred &lt;- \n  model_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  multi_predict(\n    new_data = bake(prep(rec, dat1), dat1)[c('x1', 'x2')], \n    penalty = regularization_path\n  )\n\nLet us see prediction results.\n\ndat1 |&gt; \n  bind_cols(ridge_pred) |&gt; \n  unnest(.pred)\n\n# A tibble: 28 × 5\n      x1    x2     y penalty .pred\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1    -6    -3    -3   0     -2.77\n 2    -6    -3    -3   0.333 -2.36\n 3    -6    -3    -3   0.667 -2.11\n 4    -6    -3    -3   1     -1.93\n 5    -4    -1    -2   0     -1.81\n 6    -4    -1    -2   0.333 -1.45\n 7    -4    -1    -2   0.667 -1.26\n 8    -4    -1    -2   1     -1.13\n 9    -3    -2    -1   0     -1.40\n10    -3    -2    -1   0.333 -1.24\n# ℹ 18 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regularized regression</span>"
    ]
  },
  {
    "objectID": "ch04_dimension_reduction.html",
    "href": "ch04_dimension_reduction.html",
    "title": "4  Dimension reduction",
    "section": "",
    "text": "4.1 Examples 4.10",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dimension reduction</span>"
    ]
  },
  {
    "objectID": "ch04_dimension_reduction.html#examples-4.10",
    "href": "ch04_dimension_reduction.html#examples-4.10",
    "title": "4  Dimension reduction",
    "section": "",
    "text": "4.1.1 Load data\n\ndat2 &lt;- read_csv(\"data/ch4_dat2.csv\", locale = locale(encoding = \"euc-kr\"))\n\nRows: 18 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): ID\ndbl (5): X1, X2, X3, X4, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat2\n\n# A tibble: 18 × 6\n   ID              X1    X2    X3    X4    X5\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SK증권        2.43 11.1   18.5 442.   0.9 \n 2 교보증권      3.09  9.95  29.5 239.   0.9 \n 3 대신증권      2.22  6.86  28.6 249.   0.69\n 4 대우증권      5.76 23.2   23.5 326.   1.43\n 5 동부증권      1.6   5.64  25.6 290.   1.42\n 6 메리츠증권    3.53 10.6   32.2 210.   1.17\n 7 미래에셋증권  4.26 15.6   24.4 310.   0.81\n 8 부국증권      3.86  5.5   70.7  41.4  0.81\n 9 브릿지증권    4.09  6.44  64.4  55.3  0.32\n10 삼성증권      2.73 10.7   24.4 310.   0.64\n11 서울증권      2.03  4.5   42.5 135.   0.59\n12 신영증권      1.96  8.92  18.5 441.   1.07\n13 신흥증권      3.25  7.96  40.4 147.   1.19\n14 우리투자증권  2.01 10.3   17.5 473.   1.25\n15 유화증권      2.28  3.65  63.7  57.0  0.12\n16 한양증권      4.51  7.5   63.5  57.4  0.8 \n17 한화증권      3.29 12.4   24.5 309.   0.57\n18 현대증권      1.73  7.57  19.6 410.   1.19\n\n\n\n\n4.1.2 Principal component analysis\nDefine recipe for principal component analysis. Use all variables except ID, and standardize each variable before conducting PCA.\n\nrec_pca &lt;- \n  recipe(~ ., data = dat2) |&gt; \n  step_rm(ID) |&gt; \n  step_normalize(everything()) |&gt; \n  step_pca(everything())\n\nApplying tidy() on a recipe object returns a data frame that each row represents each step.\n\ntidy(rec_pca)\n\n# A tibble: 3 × 6\n  number operation type      trained skip  id             \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;          \n1      1 step      rm        FALSE   FALSE rm_7NM5a       \n2      2 step      normalize FALSE   FALSE normalize_C1wdc\n3      3 step      pca       FALSE   FALSE pca_P5suF      \n\n\nLet us estimate PCA model.\n\npca_estimates &lt;- prep(rec_pca)\n\nApplying tidy() on estimated recipe also returns a data frame that each row represents each step. Please see that values in column trained is TRUE when passing the estimated recipe, i.e. output of prep().\n\ntidy(pca_estimates)\n\n# A tibble: 3 × 6\n  number operation type      trained skip  id             \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;          \n1      1 step      rm        TRUE    FALSE rm_7NM5a       \n2      2 step      normalize TRUE    FALSE normalize_C1wdc\n3      3 step      pca       TRUE    FALSE pca_P5suF      \n\n\nIn this example, PCA is the 3rd step. By passing argument number = 3 when calling tidy(), you can extract loadings.\n\ntidy(pca_estimates, number = 3)\n\n# A tibble: 25 × 4\n   terms   value component id       \n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 X1     0.0761 PC1       pca_P5suF\n 2 X2    -0.395  PC1       pca_P5suF\n 3 X3     0.570  PC1       pca_P5suF\n 4 X4    -0.560  PC1       pca_P5suF\n 5 X5    -0.448  PC1       pca_P5suF\n 6 X1     0.780  PC2       pca_P5suF\n 7 X2     0.565  PC2       pca_P5suF\n 8 X3     0.162  PC2       pca_P5suF\n 9 X4    -0.197  PC2       pca_P5suF\n10 X5     0.0864 PC2       pca_P5suF\n# ℹ 15 more rows\n\n\nLet’s see entire loading matrix for this example.\n\ntidy(pca_estimates, number = 3) |&gt; \n  pivot_wider(names_from = component, values_from = value)\n\n# A tibble: 5 × 7\n  terms id            PC1     PC2       PC3      PC4     PC5\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 X1    pca_P5suF  0.0761  0.780   0.000892  0.141    0.605 \n2 X2    pca_P5suF -0.395   0.565  -0.295    -0.118   -0.651 \n3 X3    pca_P5suF  0.570   0.162   0.241     0.638   -0.429 \n4 X4    pca_P5suF -0.560  -0.197  -0.257     0.748    0.150 \n5 X5    pca_P5suF -0.448   0.0864  0.888     0.00367 -0.0571\n\n\nBy additionally passing type = \"variance\" argument, you can see eigenvalues from the rows associated with terms == \"variance\", and derived statistics.\n\ntidy(pca_estimates, number = 3, type = \"variance\")\n\n# A tibble: 20 × 4\n   terms                          value component id       \n   &lt;chr&gt;                          &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;    \n 1 variance                      2.76           1 pca_P5suF\n 2 variance                      1.61           2 pca_P5suF\n 3 variance                      0.551          3 pca_P5suF\n 4 variance                      0.0641         4 pca_P5suF\n 5 variance                      0.0183         5 pca_P5suF\n 6 cumulative variance           2.76           1 pca_P5suF\n 7 cumulative variance           4.37           2 pca_P5suF\n 8 cumulative variance           4.92           3 pca_P5suF\n 9 cumulative variance           4.98           4 pca_P5suF\n10 cumulative variance           5              5 pca_P5suF\n11 percent variance             55.2            1 pca_P5suF\n12 percent variance             32.1            2 pca_P5suF\n13 percent variance             11.0            3 pca_P5suF\n14 percent variance              1.28           4 pca_P5suF\n15 percent variance              0.365          5 pca_P5suF\n16 cumulative percent variance  55.2            1 pca_P5suF\n17 cumulative percent variance  87.3            2 pca_P5suF\n18 cumulative percent variance  98.4            3 pca_P5suF\n19 cumulative percent variance  99.6            4 pca_P5suF\n20 cumulative percent variance 100              5 pca_P5suF",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dimension reduction</span>"
    ]
  },
  {
    "objectID": "ch04_dimension_reduction.html#examples-4.12",
    "href": "ch04_dimension_reduction.html#examples-4.12",
    "title": "4  Dimension reduction",
    "section": "4.2 Examples 4.12",
    "text": "4.2 Examples 4.12\n\n4.2.1 Load data\n\ndat3 &lt;- read_csv(\"data/ch4_dat3.csv\")\n\nRows: 6 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): x1, x2, x3, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat3\n\n# A tibble: 6 × 4\n     x1    x2    x3     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    -3    -3     5   -30\n2    -2    -3     7   -20\n3     0     0     4     0\n4     1     2     0     5\n5     2     2    -5    10\n6     2     2   -11    35\n\n\n\n\n4.2.2 Principal component regression (PCR)\nTo use principal component scores as input variables of a regression model, it is recommended to use workflow.\nFirst, let us define a recipe of data preprocessing including PCA. Let us create only two principal components, by passing argument num_comp = 2.\n\nrec_pca &lt;- \n  recipe(y ~ ., data = dat3) |&gt; \n  step_center(all_predictors()) |&gt; \n  step_pca(all_predictors(), num_comp = 2)\n\nLet us define a model. We will use just a default linear regression.\n\nlm_model &lt;- linear_reg()\n\nThen let us define a workflow.\n\npcr_wflow &lt;-\n  workflow() |&gt; \n  add_recipe(rec_pca) |&gt; \n  add_model(lm_model)\n\nFinally, we will train the workflow on training data.\n\npcr_fit &lt;- fit(pcr_wflow, data = dat3)\n\nSee the estimated coefficients on principal components.\n\ntidy(pcr_fit)\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) -5.02e-15     3.58  -1.40e-15  1.00  \n2 PC1          2.92e+ 0     0.530  5.51e+ 0  0.0118\n3 PC2         -2.54e+ 0     2.35  -1.08e+ 0  0.360 \n\n\n\n\n4.2.3 Prediction\nLet us predict response variable value by using the estimated PCR model by calling predict() function.\n\ndat3 |&gt; \n  bind_cols(predict(pcr_fit, new_data = dat3))\n\n# A tibble: 6 × 5\n     x1    x2    x3     y  .pred\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1    -3    -3     5   -30 -23.2 \n2    -2    -3     7   -20 -24.6 \n3     0     0     4     0  -6.95\n4     1     2     0     5   7.57\n5     2     2    -5    10  18.4 \n6     2     2   -11    35  28.8",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dimension reduction</span>"
    ]
  },
  {
    "objectID": "ch04_dimension_reduction.html#examples-4.14---4.15",
    "href": "ch04_dimension_reduction.html#examples-4.14---4.15",
    "title": "4  Dimension reduction",
    "section": "4.3 Examples 4.14 - 4.15",
    "text": "4.3 Examples 4.14 - 4.15\n\n4.3.1 Load data\n\ndat3 &lt;- read_csv(\"data/ch4_dat3.csv\")\n\nRows: 6 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): x1, x2, x3, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat3\n\n# A tibble: 6 × 4\n     x1    x2    x3     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    -3    -3     5   -30\n2    -2    -3     7   -20\n3     0     0     4     0\n4     1     2     0     5\n5     2     2    -5    10\n6     2     2   -11    35\n\n\n\n\n4.3.2 Partial least squares regression\nEstimating partial least squares(PLS) model within tidymodels framework requires some additional settings. First, you need to install {mixOmics} package to use it as an engine. {mixOmics} exists not on CRAN but on Bioconductor repository, so you should follow the installation guidance. Then, using parsnip::pls() requires installing and loading an extension package {plsmod}. Please see an example.\nNow, let us define a PLS model. Pass scale = FALSE in set_engine() when you want to use original scale for predictor variables instead of standardizing them.\n\nlibrary(plsmod)\n\npls_model &lt;- \n  pls(num_comp = 2) |&gt; \n  set_engine(\"mixOmics\", scale = FALSE) |&gt; \n  set_mode(\"regression\")\n\nLet’s estimate the PLS model.\n\npls_fit &lt;- \n  pls_model |&gt; \n  fit(y ~ ., data = dat3)\n\n\n\n4.3.3 Estimated model\nExtracting each estimated matrix from PLS model mostly requires direct access to model engine object by extract_fit_engine(); not much convinient interface through tidymodels framework.\nSee latent matrix (T):\n\npls_fit |&gt; \n  extract_fit_engine() |&gt; \n  pluck(\"variates\", \"X\")\n\n       comp1      comp2\n1 -6.3186736 -2.0166999\n2 -7.8514212 -0.5903390\n3 -3.6285452  1.5267780\n4  0.9071363  1.9538097\n5  5.7243429  0.7083091\n6 11.1671608 -1.5818579\n\n\nX-loading matrix (P):\n\npls_fit |&gt; \n  extract_fit_engine() |&gt; \n  pluck(\"mat.c\")\n\n         [,1]      [,2]\nx1  0.2539947 0.5481649\nx2  0.2860734 0.7356762\nx3 -0.9248982 0.4238016\n\n\nLoading weight matrix (W):\n\npls_fit |&gt; \n  extract_fit_engine() |&gt; \n  pluck(\"loadings\", \"X\")\n\n        comp1     comp2\nx1  0.2815251 0.6510676\nx2  0.3128056 0.6321920\nx3 -0.9071363 0.4200527\n\n\nor, simply\n\ntidy(pls_fit)\n\n# A tibble: 8 × 4\n  term   value type       component\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n1 x1     0.282 predictors         1\n2 x1     0.651 predictors         2\n3 x2     0.313 predictors         1\n4 x2     0.632 predictors         2\n5 x3    -0.907 predictors         1\n6 x3     0.420 predictors         2\n7 Y      1     outcomes           1\n8 Y      1     outcomes           2\n\n\nPlease note that loadings for y are different from the book example.\nWeight matrix related to original predictors are\n\npls_fit |&gt; \n  extract_fit_engine() |&gt; \n  pluck(\"loadings.star\", 1)\n\n         [,1]      [,2]\nx1  0.2815251 0.6629719\nx2  0.3128056 0.6454189\nx3 -0.9071363 0.3816945\n\n\n\n\n4.3.4 Prediction\nPredicting expected response variable value is easy within tidymodels framework, by calling predict() function.\n\ndat3 |&gt; \n  bind_cols(predict(pls_fit, new_data = dat3))\n\n# A tibble: 6 × 5\n     x1    x2    x3     y  .pred\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1    -3    -3     5   -30 -23.5 \n2    -2    -3     7   -20 -24.5 \n3     0     0     4     0  -6.82\n4     1     2     0     5   7.52\n5     2     2    -5    10  18.5 \n6     2     2   -11    35  28.7",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dimension reduction</span>"
    ]
  },
  {
    "objectID": "ch05_classification.html",
    "href": "ch05_classification.html",
    "title": "5  Classification",
    "section": "",
    "text": "5.1 Example 5.2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "ch05_classification.html#example-5.2",
    "href": "ch05_classification.html#example-5.2",
    "title": "5  Classification",
    "section": "",
    "text": "5.1.1 Load data\nTo estimate classification models, you first need to convert outcome variable to be a factor, if it is a numeric in original data.\n\ndat1 &lt;- read_csv(\"data/ch7_dat1.csv\") |&gt; \n  mutate(class = as.factor(class))\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): ID, X1, X2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat1\n\n# A tibble: 9 × 4\n     ID    X1    X2 class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n1     1     5     7 1    \n2     2     4     3 2    \n3     3     7     8 2    \n4     4     8     6 2    \n5     5     3     6 1    \n6     6     2     5 1    \n7     7     6     6 1    \n8     8     9     6 2    \n9     9     5     4 2    \n\n\n\n\n5.1.2 Split data\nLet us divide data into two fold: training and testing data. Within tidymodels framework, {rsamples} package, a part of {tidymodels} provides functions to split data.\ninitial_split() randomly split data into training and testing data, while initial_time_split() take first rows of data as training and last rows of data as testing data. To be consistent with a book example, let us use initial_time_split() here.\nIn this example, let us use 8 data points as training data, and just one data point as testing data.\n\ndat1_split &lt;- initial_time_split(dat1, prop = 8 / 9)\ndat_train &lt;- training(dat1_split)\ndat_test &lt;- testing(dat1_split)\n\n\n\n\n\n\n\nNote\n\n\n\nA book examples used 7 data points as training data, but we are using 8 here due to a parameter setting mechanism in tidymodels framework. Within tidymodels framework, 8 data points are the minimum number of data points to use 3 neighborhoods. If you use 7 data points as training data, tidymodels will automatically reset the number of neighbors to be 2. For more details, please see https://parsnip.tidymodels.org/reference/details_nearest_neighbor_kknn.html.\n\n\n\n\n5.1.3 3-NN model estimation\nTidymodels framework uses {kknn} as an engine of k-nearest-neighbor models for both classification and regression. After installing {kknn} package, call nearest_neighbor() with neighbors argument to specify number of neighbors to use in estimation. You must specify mode of the model to be either \"classification\" or \"regression\". In this example, use \"classification\" mode.\n\nknn_model &lt;- \n  nearest_neighbor(neighbors = 3) |&gt; \n  set_engine(\"kknn\", scale = FALSE) |&gt; \n  set_mode(\"classification\")\n\nThen, estimate the model with fit() function.\n\nknn_fit &lt;- \n  knn_model |&gt; \n  fit(class ~ X1 + X2, data = dat_train)\n\nLet us check estimated results on training data.\n\ndat_train |&gt; \n  bind_cols(\n    knn_fit |&gt; \n      extract_fit_engine() |&gt; \n      pluck(\"fitted.values\") |&gt; \n      set_names(\"estimated_class\")\n  )\n\n# A tibble: 8 × 5\n     ID    X1    X2 class estimated_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;          \n1     1     5     7 1     1              \n2     2     4     3 2     1              \n3     3     7     8 2     1              \n4     4     8     6 2     2              \n5     5     3     6 1     1              \n6     6     2     5 1     1              \n7     7     6     6 1     1              \n8     8     9     6 2     2              \n\n\n\n\n5.1.4 Prediction\nLet us make a prediction on testing data, by calling predict() function.\n\ndat_test |&gt; \n  bind_cols(\n    predict(knn_fit, new_data = dat_test)\n  )\n\n# A tibble: 1 × 5\n     ID    X1    X2 class .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;      \n1     9     5     4 2     2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "ch05_classification.html#examples-5.3---5.4",
    "href": "ch05_classification.html#examples-5.3---5.4",
    "title": "5  Classification",
    "section": "5.2 Examples 5.3 - 5.4",
    "text": "5.2 Examples 5.3 - 5.4\n\n5.2.1 Load data\n\ndat3 &lt;- read_csv(\"data/ch5_dat3.csv\")\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (3): ID, age_gr, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat3\n\n# A tibble: 9 × 4\n     ID gender age_gr class\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     1 M           2     1\n2     2 M           2     2\n3     3 M           3     1\n4     4 M           4     1\n5     5 F           1     1\n6     6 F           2     2\n7     7 F           2     1\n8     8 F           3     2\n9     9 F           4     2\n\n\n\n\n5.2.2 Convert data type\nFirst, convert output to be a factor, because you are going to build a classification model. Please use typical data wrangling instead of using recipe when transforming output variable.\n\ndat3 &lt;- \n  dat3 |&gt; \n  mutate(class = as.factor(class))\n\nDefine a recipe to convert categorical input variable into factors by using recipe. When original variable type is numeric, use step_num2factor(). When original variable type is character, use step_string2factor().\n\nnb_rec &lt;- \n  recipe(class ~ gender + age_gr, data = dat3) |&gt; \n  step_num2factor(age_gr, levels = c(\"1\", \"2\", \"3\", \"4\")) |&gt; \n  step_string2factor(gender)\n\n\n\n\n\n\n\nNote\n\n\n\nIf you include output variable type conversion within a recipe and include it in a workflow, predict() will return an error because it removes output variable from new_data before applying a recipe.\n\n\n\n\n5.2.3 Ex 5.3: Naive bayes clssification\n\n5.2.3.1 Estimate a classifier\nLet us use parsnip::naive_Bayes() to define naive bayes model. By default, it uses {klaR} engine and requires installation and loading {discrim} package to fit the model. Please find more details here.\n\nlibrary(discrim)\n\n\nAttaching package: 'discrim'\n\n\nThe following object is masked from 'package:dials':\n\n    smoothness\n\nnb_model &lt;- naive_Bayes(smoothness = 0) |&gt; \n  set_engine(\"klaR\") # use {klaR} engine; this is default engine\n\nYou can check engine-level model fitting function template by calling translate() function.\n\nnb_model |&gt; translate()\n\nNaive Bayes Model Specification (classification)\n\nMain Arguments:\n  smoothness = 0\n\nComputational engine: klaR \n\nModel fit template:\ndiscrim::klar_bayes_wrapper(x = missing_arg(), y = missing_arg(), \n    adjust = 0, usekernel = TRUE)\n\n\nLet us define workflow and train the model.\n\nnb_fit &lt;- \n  workflow() |&gt; \n  add_recipe(nb_rec) |&gt; \n  add_model(nb_model) |&gt; \n  fit(dat3)\n\nnb_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: naive_Bayes()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_num2factor()\n• step_string2factor()\n\n── Model ───────────────────────────────────────────────────────────────────────\n$apriori\ngrouping\n        1         2 \n0.5555556 0.4444444 \n\n$tables\n$tables$gender\n        var\ngrouping    F    M\n       1 0.40 0.60\n       2 0.75 0.25\n\n$tables$age_gr\n        var\ngrouping    1    2    3    4\n       1 0.20 0.40 0.20 0.20\n       2 0.00 0.50 0.25 0.25\n\n\n$levels\n[1] \"1\" \"2\"\n\n$call\nNaiveBayes.default(x = ~maybe_data_frame(x), grouping = ~y, usekernel = ~TRUE, \n    adjust = ~0)\n\n$x\n  gender age_gr\n1      M      2\n2      M      2\n3      M      3\n4      M      4\n5      F      1\n6      F      2\n7      F      2\n8      F      3\n9      F      4\n\n$usekernel\n[1] TRUE\n\n$varnames\n[1] \"gender\" \"age_gr\"\n\nattr(,\"class\")\n[1] \"NaiveBayes\"\n\n\n\n\n5.2.3.2 Prediction\nLet us predict posterior probabilities and predict class as well. Both can by done by calling predict() function, where you can specify type = \"prob\" for posterior probability prediction and type = \"class\" for class prediction.\n\nresults &lt;- dat3 |&gt; \n  bind_cols(\n    predict(nb_fit, new_data = dat3, type = \"prob\"),\n    predict(nb_fit, new_data = dat3, type = \"class\")\n  )\n\nresults\n\n# A tibble: 9 × 7\n     ID gender age_gr class .pred_1 .pred_2 .pred_class\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;      \n1     1 M           2 1       0.706 0.294   1          \n2     2 M           2 2       0.706 0.294   1          \n3     3 M           3 1       0.706 0.294   1          \n4     4 M           4 1       0.706 0.294   1          \n5     5 F           1 1       0.993 0.00744 1          \n6     6 F           2 2       0.348 0.652   2          \n7     7 F           2 1       0.348 0.652   2          \n8     8 F           3 2       0.348 0.652   2          \n9     9 F           4 2       0.348 0.652   2          \n\n\n\n\n5.2.3.3 Use {naivebayes} engine\nInstead of default engine {klaR}, let us use different engine from {naivebayes} package. The only change that you need to make is engine name argument in set_engine() when defining a model. It provides an identical results.\n\nlibrary(discrim)\n\nnb_model &lt;- naive_Bayes(smoothness = 0) |&gt; \n  set_engine(\"naivebayes\") # use {naivebayes} engine\n\nnb_model |&gt; translate()\n\nNaive Bayes Model Specification (classification)\n\nMain Arguments:\n  smoothness = 0\n\nComputational engine: naivebayes \n\nModel fit template:\nnaivebayes::naive_bayes(x = missing_arg(), y = missing_arg(), \n    adjust = 0, usekernel = TRUE)\n\nnb_fit &lt;- \n  workflow() |&gt; \n  add_recipe(nb_rec) |&gt; \n  add_model(nb_model) |&gt; \n  fit(dat3)\n\nWarning: naive_bayes(): Feature age_gr - zero probabilities are present.\nConsider Laplace smoothing.\n\nnb_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: naive_Bayes()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_num2factor()\n• step_string2factor()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\n================================= Naive Bayes ==================================\n\nCall:\nnaive_bayes.default(x = maybe_data_frame(x), y = y, usekernel = TRUE, \n    adjust = ~0)\n\n-------------------------------------------------------------------------------- \n \nLaplace smoothing: 0\n\n-------------------------------------------------------------------------------- \n \nA priori probabilities: \n\n        1         2 \n0.5555556 0.4444444 \n\n-------------------------------------------------------------------------------- \n \nTables: \n\n-------------------------------------------------------------------------------- \n:: gender (Bernoulli) \n-------------------------------------------------------------------------------- \n      \ngender    1    2\n     F 0.40 0.75\n     M 0.60 0.25\n\n-------------------------------------------------------------------------------- \n:: age_gr (Categorical) \n-------------------------------------------------------------------------------- \n      \nage_gr    1    2\n     1 0.20 0.00\n     2 0.40 0.50\n     3 0.20 0.25\n     4 0.20 0.25\n\n--------------------------------------------------------------------------------\n\nresults &lt;- dat3 |&gt; \n  bind_cols(\n    predict(nb_fit, new_data = dat3, type = \"prob\"),\n    predict(nb_fit, new_data = dat3, type = \"class\")\n  )\n\nresults\n\n# A tibble: 9 × 7\n     ID gender age_gr class .pred_1 .pred_2 .pred_class\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;      \n1     1 M           2 1       0.706 0.294   1          \n2     2 M           2 2       0.706 0.294   1          \n3     3 M           3 1       0.706 0.294   1          \n4     4 M           4 1       0.706 0.294   1          \n5     5 F           1 1       0.993 0.00744 1          \n6     6 F           2 2       0.348 0.652   2          \n7     7 F           2 1       0.348 0.652   2          \n8     8 F           3 2       0.348 0.652   2          \n9     9 F           4 2       0.348 0.652   2          \n\n\n\n\n\n5.2.4 Ex 5.4: Performance evaluation\n{yardstick}, which is a part of {tidymodels} framework, provides functions to evaluate performance of classification and regression models. Here, let us take a look at several classification performance metrics.\n\n5.2.4.1 Confusion matrix\nCreate confusion matrix by calling conf_mat() with classification result data frame. For other required arguments, truth represents a column name of actual class labels and estimate represents a column name of predicted class labels.\n\nresults |&gt; \n  conf_mat(truth = class, estimate = .pred_class)\n\n          Truth\nPrediction 1 2\n         1 4 1\n         2 1 3\n\n\n\n\n5.2.4.2 Accuracy\nEvaluate simple classification accuracy by accuracy()\n\nresults |&gt; \n  accuracy(truth = class, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.778\n\n\n\n\n5.2.4.3 Sensitivity\nUse sens(). Pass event_level argument if needs to explicitly define “event” class label. It argument is only applicable to binary classification, and the value should be either \"first\" or \"second\".\n\nresults |&gt; \n  sens(truth = class, estimate = .pred_class, event_level = \"first\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary           0.8\n\n\n\n\n5.2.4.4 Specificity\nUse spec().\n\nresults |&gt; \n  spec(truth = class, estimate = .pred_class, event_level = \"first\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary          0.75\n\n\n\n\n5.2.4.5 F1-score\nUse f_meas()\n\nresults |&gt; \n  f_meas(truth = class, estimate = .pred_class, event_level = \"first\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary           0.8\n\n\n\n\n5.2.4.6 Evaluate multiple metrics\n{yardstick} provides a convenient way to evaluate multiple metrics.\nFirst, create a set of metrics to compute by calling metric_set() with metric functions of interest as arguments.\n\nmultiple_metrics &lt;- metric_set(accuracy, sens, spec, f_meas)\n\nLet’s print the object.\n\nmultiple_metrics\n\nA metric set, consisting of:\n- `accuracy()`, a class metric | direction: maximize\n- `sens()`, a class metric     | direction: maximize\n- `spec()`, a class metric     | direction: maximize\n- `f_meas()`, a class metric   | direction: maximize\n\n\nBy looking at classes and a type of multiple_metrics object, you can see that it is a callable function.\n\nclass(multiple_metrics)\n\n[1] \"class_prob_metric_set\" \"metric_set\"            \"function\"             \n\ntypeof(multiple_metrics)\n\n[1] \"closure\"\n\n\nNow, call the function to compute multiple metrics of interest.\n\nresults |&gt; \n  multiple_metrics(truth = class, estimate = .pred_class, event_level = \"first\")\n\n# A tibble: 4 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.778\n2 sens     binary         0.8  \n3 spec     binary         0.75 \n4 f_meas   binary         0.8",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "ch06_logistic_regression.html",
    "href": "ch06_logistic_regression.html",
    "title": "6  Logistic regression",
    "section": "",
    "text": "6.1 Examples 6.1, 6.3",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "ch06_logistic_regression.html#examples-6.1-6.3",
    "href": "ch06_logistic_regression.html#examples-6.1-6.3",
    "title": "6  Logistic regression",
    "section": "",
    "text": "6.1.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch6_dat1.csv\")\n\nRows: 15 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Class\ndbl (3): Break, Sleep, Circle\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLogistic regression requires outcome variable to be a factor.\n\ndat1 &lt;-\n  dat1 |&gt; \n  mutate(Class = factor(Class, levels = c(\"Average\", \"Excellent\")))\n\n\n\n6.1.2 Ex 6.1: Logistic regression model\nDefine a model type to be logistic regression, by calling logistic_reg(). By default, it uses {glm} engine and \"classification\" mode.\n\nlogistic_model &lt;- logistic_reg()\n\nLet us train the model by using dat1 data. Let us use workflow pipeline. Because we do not have a recipe, we will add formula instead.\n\nlogistic_fit &lt;- \n  workflow() |&gt; \n  add_formula(Class ~ Break + Sleep + Circle) |&gt; \n  add_model(logistic_model) |&gt; \n  fit(dat1)\n\nlogistic_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nClass ~ Break + Sleep + Circle\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n(Intercept)        Break        Sleep       Circle  \n    -30.511        2.031        3.471        2.414  \n\nDegrees of Freedom: 14 Total (i.e. Null);  11 Residual\nNull Deviance:      20.19 \nResidual Deviance: 10.42    AIC: 18.42\n\n\nCheck statistics for each coefficients.\n\ntidy(logistic_fit)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   -30.5      18.0      -1.69  0.0904\n2 Break           2.03      1.98      1.02  0.306 \n3 Sleep           3.47      2.07      1.67  0.0944\n4 Circle          2.41      1.40      1.73  0.0838\n\n\nMake a prediction by calling predict() function.\n\nresults &lt;- \n  dat1 |&gt; \n  bind_cols(\n    logit = predict(logistic_fit, new_data = dat1, type = \"raw\"),\n    predict(logistic_fit, new_data = dat1, type = \"prob\"),\n    predict(logistic_fit, new_data = dat1, type = \"class\")\n  )\n\n\n\n6.1.3 Ex 6.3: Gompit and Probit\nPass engine-specific argument to use a specific link function of glm().\n\n6.1.3.1 Gompit\n\ngompit_model &lt;- \n  logistic_reg() |&gt; \n  set_engine(\"glm\", family = binomial(\"cloglog\"))\n\ngompit_fit &lt;- \n  workflow() |&gt; \n  add_formula(Class ~ Break + Sleep + Circle) |&gt; \n  add_model(gompit_model) |&gt; \n  fit(dat1)\n\ntidy(gompit_fit)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   -26.4      15.0     -1.76   0.0786\n2 Break           1.35      1.50     0.898  0.369 \n3 Sleep           2.97      1.71     1.73   0.0828\n4 Circle          2.04      1.07     1.91   0.0567\n\n\n\n\n6.1.3.2 Normit\n\nnormit_model &lt;- \n  logistic_reg() |&gt; \n  set_engine(\"glm\", family = binomial(\"probit\"))\n\nnormit_fit &lt;- \n  workflow() |&gt; \n  add_formula(Class ~ Break + Sleep + Circle) |&gt; \n  add_model(normit_model) |&gt; \n  fit(dat1)\n\ntidy(normit_fit)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   -17.9      9.91      -1.80  0.0717\n2 Break           1.26     1.13       1.12  0.264 \n3 Sleep           2.03     1.14       1.78  0.0754\n4 Circle          1.41     0.780      1.81  0.0697",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "ch06_logistic_regression.html#examples-6.4",
    "href": "ch06_logistic_regression.html#examples-6.4",
    "title": "6  Logistic regression",
    "section": "6.2 Examples 6.4",
    "text": "6.2 Examples 6.4\n\n6.2.1 Load data\n\ndat2 &lt;- \n  read_csv(\"data/ch6_dat2.csv\") |&gt; \n  mutate(Y = factor(Y, levels = c(1, 2, 3)))\n\nRows: 18 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): X1, X2, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n6.2.2 Estimate multinomial model\nDefine a multinomial model by calling multinom_reg(). By default, it uses {nnet} engine.\n\nmn_model &lt;- multinom_reg()\n\nThen fit a model on training data.\n\nmn_fit &lt;- \n  mn_model |&gt; \n  fit(Y ~ X1 + X2, data = dat2)\n\nLet’s see the estimated coefficients.\n\ntidy(mn_fit)\n\n# A tibble: 6 × 6\n  y.level term        estimate std.error statistic p.value\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 2       (Intercept)  -74.3      52.5       -1.42  0.157 \n2 2       X1             0.805     0.746      1.08  0.281 \n3 2       X2            13.0       9.47       1.37  0.170 \n4 3       (Intercept)   85.8      69.1        1.24  0.214 \n5 3       X1            -1.48      0.885     -1.67  0.0953\n6 3       X2           -14.3      13.0       -1.10  0.273 \n\n\n\n\n6.2.3 Prediction\nMake a prediction by calling predict() function.\n\nresults &lt;- \n  dat2 |&gt; \n  bind_cols(\n    predict(mn_fit, new_data = dat2, type = \"prob\"),\n    predict(mn_fit, new_data = dat2, type = \"class\")\n  )\n\nresults\n\n# A tibble: 18 × 7\n      X1    X2 Y     .pred_1 .pred_2 .pred_3 .pred_class\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;      \n 1  9.33  5.02 1       0.371  0.0752 0.554   3          \n 2  9.91  5.01 1       0.496  0.141  0.363   1          \n 3 11.9   4.94 1       0.600  0.335  0.0649  1          \n 4 11.5   5.12 1       0.185  0.813  0.00253 2          \n 5 11.7   5.03 1       0.393  0.591  0.0163  2          \n 6 12.4   4.94 2       0.522  0.453  0.0250  1          \n 7 10.3   5.13 2       0.339  0.636  0.0244  2          \n 8 10.2   4.87 1       0.207  0.0116 0.782   3          \n 9  9.83  5.13 2       0.414  0.524  0.0615  2          \n10 10.8   4.94 3       0.564  0.131  0.305   1          \n11 10.6   4.93 3       0.492  0.0840 0.425   1          \n12  8.66  5.02 3       0.195  0.0230 0.782   3          \n13  9.59  5.01 3       0.418  0.0917 0.490   3          \n14  9.35  4.94 3       0.178  0.0130 0.809   3          \n15 10.2   5.12 2       0.385  0.576  0.0382  2          \n16 12.2   4.93 2       0.584  0.371  0.0454  1          \n17  9.8   5    1       0.450  0.103  0.447   1          \n18  8.8   5.01 3       0.205  0.0238 0.771   3          \n\n\n\n\n6.2.4 Confusion matrix\nCreate a confusion matrix by calling conf_mat() from {yardstick}.\n\nconf_mat(results, truth = Y, estimate = .pred_class)\n\n          Truth\nPrediction 1 2 3\n         1 3 2 2\n         2 2 3 0\n         3 2 0 4",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "ch07_da.html",
    "href": "ch07_da.html",
    "title": "7  Discriminant analysis",
    "section": "",
    "text": "7.1 Example 7.4",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Discriminant analysis</span>"
    ]
  },
  {
    "objectID": "ch07_da.html#example-7.4",
    "href": "ch07_da.html#example-7.4",
    "title": "7  Discriminant analysis",
    "section": "",
    "text": "7.1.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch7_dat1.csv\") |&gt; \n  mutate(class = as.factor(class))\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): ID, X1, X2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n7.1.2 Linear discriminant analysis\nDefine a model for linear discriminant analysis by calling discrim_linear(). The default engine is {MASS}. Linear discriminant analysis with {MASS} engine requires installation and loading {discrim} package. Let us set engine-specific argument prior = c(0.5, 0.5) to explicitly set prior probabilities instead of using proportions within training data.\n\nlibrary(discrim)\n\n\nAttaching package: 'discrim'\n\n\nThe following object is masked from 'package:dials':\n\n    smoothness\n\nlda_model &lt;- \n  discrim_linear() |&gt; \n  set_engine(\"MASS\", prior = c(0.5, 0.5))\n\nLet’s check model fit template.\n\ntranslate(lda_model)\n\nLinear Discriminant Model Specification (classification)\n\nEngine-Specific Arguments:\n  prior = c(0.5, 0.5)\n\nComputational engine: MASS \n\nModel fit template:\nMASS::lda(formula = missing_arg(), data = missing_arg(), prior = c(0.5, \n    0.5))\n\n\nLet’s train the model.\n\nlda_fit &lt;- \n  lda_model |&gt; \n  fit(class ~ X1 + X2, data = dat1)\n\ntidy() function does not support this model, so let us just print the model.\n\nlda_fit\n\nparsnip model object\n\nCall:\nlda(class ~ X1 + X2, data = data, prior = ~c(0.5, 0.5))\n\nPrior probabilities of groups:\n  1   2 \n0.5 0.5 \n\nGroup means:\n   X1  X2\n1 4.0 6.0\n2 6.6 5.4\n\nCoefficients of linear discriminants:\n          LD1\nX1  0.6850490\nX2 -0.7003859\n\n\n\n\n7.1.3 Prediction\nLet us make a prediction on training data.\n\nresults &lt;-\n  dat1 |&gt; \n  bind_cols(\n    predict(lda_fit, dat1, type = \"prob\"),\n    predict(lda_fit, dat1, type = \"class\")\n  )\n\nresults\n\n# A tibble: 9 × 7\n     ID    X1    X2 class .pred_1 .pred_2 .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;      \n1     1     5     7 1     0.921    0.0789 1          \n2     2     4     3 2     0.0995   0.900  2          \n3     3     7     8 2     0.728    0.272  1          \n4     4     8     6 2     0.0264   0.974  2          \n5     5     3     6 1     0.981    0.0192 1          \n6     6     2     5 1     0.980    0.0199 1          \n7     7     6     6 1     0.356    0.644  2          \n8     8     9     6 2     0.00596  0.994  2          \n9     9     5     4 2     0.103    0.897  2          \n\n\nLet us evaluate the classification performance. Here, .pred_1 is additionally passed as an argument to compute roc_auc().\n\nmetrics_multi &lt;- metric_set(accuracy, sens, spec, f_meas, roc_auc)\nmetrics_multi(results, truth = class, estimate = .pred_class, .pred_1)\n\n# A tibble: 5 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.778\n2 sens     binary         0.75 \n3 spec     binary         0.8  \n4 f_meas   binary         0.75 \n5 roc_auc  binary         0.95",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Discriminant analysis</span>"
    ]
  },
  {
    "objectID": "ch07_da.html#example-7.6",
    "href": "ch07_da.html#example-7.6",
    "title": "7  Discriminant analysis",
    "section": "7.2 Example 7.6",
    "text": "7.2 Example 7.6\n\n7.2.1 Load data\n\ndat1 &lt;- read_csv(\"data/ch7_dat1.csv\") |&gt; \n  mutate(class = as.factor(class))\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): ID, X1, X2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n7.2.2 Quadratic discriminant analysis\nAlmost identical to linear discriminant analysis, except that you should use discrim_quad().\n\nlibrary(discrim)\n\nqda_model &lt;- \n  discrim_quad() |&gt; \n  set_engine(\"MASS\", prior = c(0.5, 0.5))\n\ntranslate(qda_model)\n\nQuadratic Discriminant Model Specification (classification)\n\nEngine-Specific Arguments:\n  prior = c(0.5, 0.5)\n\nComputational engine: MASS \n\nModel fit template:\nMASS::qda(formula = missing_arg(), data = missing_arg(), prior = c(0.5, \n    0.5))\n\nqda_fit &lt;- \n  qda_model |&gt; \n  fit(class ~ X1 + X2, data = dat1)\n\nqda_fit\n\nparsnip model object\n\nCall:\nqda(class ~ X1 + X2, data = data, prior = ~c(0.5, 0.5))\n\nPrior probabilities of groups:\n  1   2 \n0.5 0.5 \n\nGroup means:\n   X1  X2\n1 4.0 6.0\n2 6.6 5.4\n\n\n\n\n7.2.3 Prediction\n\nresults &lt;-\n  dat1 |&gt; \n  bind_cols(\n    predict(qda_fit, dat1, type = \"prob\"),\n    predict(qda_fit, dat1, type = \"class\")\n  )\n\nresults\n\n# A tibble: 9 × 7\n     ID    X1    X2 class   .pred_1 .pred_2 .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;      \n1     1     5     7 1     0.920     0.0799  1          \n2     2     4     3 2     0.0000286 1.00    2          \n3     3     7     8 2     0.368     0.632   2          \n4     4     8     6 2     0.0398    0.960   2          \n5     5     3     6 1     0.992     0.00814 1          \n6     6     2     5 1     0.991     0.00905 1          \n7     7     6     6 1     0.539     0.461   1          \n8     8     9     6 2     0.00722   0.993   2          \n9     9     5     4 2     0.00218   0.998   2          \n\nmetrics_multi &lt;- metric_set(accuracy, sens, spec, f_meas, roc_auc)\nmetrics_multi(results, truth = class, estimate = .pred_class, .pred_1)\n\n# A tibble: 5 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary             1\n2 sens     binary             1\n3 spec     binary             1\n4 f_meas   binary             1\n5 roc_auc  binary             1",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Discriminant analysis</span>"
    ]
  },
  {
    "objectID": "ch07_da.html#example-7.7",
    "href": "ch07_da.html#example-7.7",
    "title": "7  Discriminant analysis",
    "section": "7.3 Example 7.7",
    "text": "7.3 Example 7.7\n\n7.3.1 Load data\n\niris &lt;- read_csv(\"data/iris.csv\") |&gt; \n  mutate(Species = as.factor(Species))\n\nRows: 150 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n7.3.2 Train/Test split\nLet us make 30 observations from each species as training data, while let remaining 20 observations be testing data.\n\niris_split &lt;- initial_split(iris, prop = 30 / 50, strata = Species)\ntraining_dat &lt;- training(iris_split)\ntesting_dat &lt;- testing(iris_split)\n\n\n\n\n\n\n\nNote\n\n\n\nUnfortunately, this does not provide an exact results to a book example. initial_time_split() does not consume strata argument.\nThe following code will provide the exactly same results to the book example.\niris_split &lt;- iris |&gt; \n  split(iris$Species) |&gt; \n  map(\\(x) initial_time_split(x, prop = 30 / 50))\n\ntraining_dat &lt;- map(iris_split, training) |&gt; bind_rows()\ntesting_dat &lt;- map(iris_split, testing) |&gt; bind_rows()\n\n\n\n\n7.3.3 Linear discriminant analysis\nEstimate LDA model on training data.\n\nlibrary(discrim)\n\nlda_fit &lt;- \n  discrim_linear() |&gt; \n  fit(Species ~ ., data = training_dat)\n\nMake a prediction on testing data.\n\nresults &lt;- \n  testing_dat |&gt; \n  bind_cols(\n    predict(lda_fit, testing_dat, type = \"class\")\n  )\n\nresults\n\n# A tibble: 60 × 6\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .pred_class\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;      \n 1          4.7         3.2          1.3         0.2 setosa  setosa     \n 2          5           3.6          1.4         0.2 setosa  setosa     \n 3          5.4         3.7          1.5         0.2 setosa  setosa     \n 4          4.8         3.4          1.6         0.2 setosa  setosa     \n 5          4.8         3            1.4         0.1 setosa  setosa     \n 6          5.4         3.9          1.3         0.4 setosa  setosa     \n 7          5.1         3.5          1.4         0.3 setosa  setosa     \n 8          5.1         3.8          1.5         0.3 setosa  setosa     \n 9          5           3            1.6         0.2 setosa  setosa     \n10          5.2         3.4          1.4         0.2 setosa  setosa     \n# ℹ 50 more rows\n\n\nConfusion matrix\n\nconf_mat(results, truth = Species, estimate = .pred_class)\n\n            Truth\nPrediction   setosa versicolor virginica\n  setosa         20          0         0\n  versicolor      0         20         0\n  virginica       0          0        20",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Discriminant analysis</span>"
    ]
  },
  {
    "objectID": "ch08_tree.html",
    "href": "ch08_tree.html",
    "title": "8  Decision tree",
    "section": "",
    "text": "8.1 Examples 8.2 - 8.7",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Decision tree</span>"
    ]
  },
  {
    "objectID": "ch08_tree.html#examples-8.2---8.7",
    "href": "ch08_tree.html#examples-8.2---8.7",
    "title": "8  Decision tree",
    "section": "",
    "text": "8.1.1 Load data\n\ndf_train &lt;- read_csv(\"data/ch8_dat1.csv\") |&gt; \n  mutate(class = factor(class, levels = c(1, 2)))\n\nRows: 10 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x1, x2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf_test &lt;- read_csv(\"data/ch8_dat2.csv\") |&gt; \n  mutate(class = factor(class, levels = c(1, 2)))\n\nRows: 6 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x1, x2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n8.1.2 Ex 8.3: Estimate a maximal tree\nDefine a model for decision tree. decision_tree() uses {rpart} package as a default engine. Pass cost_complexity = 0 to split a node even if misclassification cost does not decrease. In addition, use min_n = 2 argument to try to split a node when the node has two observations.\n\ntree_model &lt;- \n  decision_tree(\n    mode = \"classification\", \n    cost_complexity = 0,\n    min_n = 2\n  )\n\nEstimate the model by using training data.\n\ntree_fit &lt;- tree_model |&gt; \n  fit(class ~ x1 + x2, data = df_train)\n\nLet us see the estimated maximal tree.\n\ntree_fit\n\nparsnip model object\n\nn= 10 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 10 5 1 (0.5000000 0.5000000)  \n   2) x2&gt;=5.5 3 0 1 (1.0000000 0.0000000) *\n   3) x2&lt; 5.5 7 2 2 (0.2857143 0.7142857)  \n     6) x1&lt; 1.5 1 0 1 (1.0000000 0.0000000) *\n     7) x1&gt;=1.5 6 1 2 (0.1666667 0.8333333)  \n      14) x2&gt;=4.5 2 1 1 (0.5000000 0.5000000)  \n        28) x1&lt; 3 1 0 1 (1.0000000 0.0000000) *\n        29) x1&gt;=3 1 0 2 (0.0000000 1.0000000) *\n      15) x2&lt; 4.5 4 0 2 (0.0000000 1.0000000) *\n\n\n\n\n8.1.3 Ex 8.7: Prediction\nCall predict() function to predict classes of test data.\n\nresults &lt;- df_test |&gt; \n  bind_cols(\n    predict(tree_fit, new_data = df_test)\n  )\n\nresults\n\n# A tibble: 6 × 4\n     x1    x2 class .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;      \n1     1     5 1     1          \n2     0     5 1     1          \n3     3     4 2     2          \n4     4     3 2     2          \n5     2     7 1     1          \n6     1     4 2     1          \n\n\nEvaluate the accuracy of classification on test data.\n\naccuracy(results, truth = class, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.833\n\n\n\n\n8.1.4 Tune tree_depth parameter\ntree_depth is one of hyperparameters of a decision tree, and you may want to determine the best hyperparameter value to use. This can be done by setting parameter tree_depth to be a placeholder tune().\n\ntree_model &lt;- \n  decision_tree(\n    mode = \"classification\", \n    tree_depth = tune(),\n    cost_complexity = 0,\n    min_n = 2\n  )\n\nLet’s recreate a workflow. You can see tree_depth = tune() in the model main arguments section.\n\ntree_wflow &lt;- \n  workflow() |&gt; \n  add_formula(class ~ x1 + x2) |&gt; \n  add_model(tree_model)\n\ntree_wflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nclass ~ x1 + x2\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0\n  tree_depth = tune()\n  min_n = 2\n\nComputational engine: rpart \n\n\nLet us see what parameters are subject to tune.\n\ntree_set &lt;- extract_parameter_set_dials(tree_wflow)\ntree_set\n\nCollection of 1 parameters for tuning\n\n identifier       type    object\n tree_depth tree_depth nparam[+]\n\n\nYou can see a specific range of the parameter values by calling extract_parameter_dials() with specifying parameter name of interest to parameter argument.\n\nextract_parameter_dials(tree_set, parameter = \"tree_depth\")\n\nTree Depth (quantitative)\nRange: [1, 15]\n\n\nEach parameter has default range to explore, but you can override the range by calling update(). Let’s set to try tree_depth from 1 to 4.\n\ntree_set &lt;-\n  tree_set |&gt; \n  update(tree_depth = tree_depth(c(1L, 4L)))\n\nextract_parameter_dials(tree_set, parameter = \"tree_depth\")\n\nTree Depth (quantitative)\nRange: [1, 4]\n\n\nLet’s evaluate classification performance by using cross-validation. Here we create a cross-validation dataset by calling vfold_cv(). We will use 5-folds cross-validation by setting v = 5 and will create 25 different cross-validation datasets by setting repeats = 25. Additionally, let us set strata = class so that each fold has roughly same distribution of class values. This step would take few seconds due to large amount of computation.\n\nset.seed(892347)\n\nfolds &lt;- vfold_cv(df_train, v = 5, repeats = 25, strata = class)\n\nsearch_grid &lt;- \n  tree_wflow |&gt; \n  tune_grid(\n    resamples = folds,\n    param_info = tree_set\n  )\n\nLet’s see summarized performance by each tree_depth value.\n\nestimates &lt;- collect_metrics(search_grid)\nestimates\n\n# A tibble: 12 × 7\n   tree_depth .metric     .estimator  mean     n std_err .config             \n        &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1          3 accuracy    binary     0.544   125  0.0205 Preprocessor1_Model1\n 2          3 brier_class binary     0.441   125  0.0206 Preprocessor1_Model1\n 3          3 roc_auc     binary     0.576   125  0.0228 Preprocessor1_Model1\n 4          2 accuracy    binary     0.524   125  0.0226 Preprocessor1_Model2\n 5          2 brier_class binary     0.425   125  0.0224 Preprocessor1_Model2\n 6          2 roc_auc     binary     0.608   125  0.0276 Preprocessor1_Model2\n 7          4 accuracy    binary     0.576   125  0.0228 Preprocessor1_Model3\n 8          4 brier_class binary     0.424   125  0.0228 Preprocessor1_Model3\n 9          4 roc_auc     binary     0.576   125  0.0228 Preprocessor1_Model3\n10          1 accuracy    binary     0.608   125  0.0276 Preprocessor1_Model4\n11          1 brier_class binary     0.374   125  0.0231 Preprocessor1_Model4\n12          1 roc_auc     binary     0.608   125  0.0276 Preprocessor1_Model4\n\n\nYou can also plot the performance.\n\nautoplot(search_grid)\n\n\n\n\n\n\n\n\nLet’s see best performing tree_depth values based on classification accuracy. This will show tree_depth values in a descending order of classification accuracy.\n\nshow_best(search_grid, metric = \"accuracy\")\n\n# A tibble: 4 × 7\n  tree_depth .metric  .estimator  mean     n std_err .config             \n       &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1          1 accuracy binary     0.608   125  0.0276 Preprocessor1_Model4\n2          4 accuracy binary     0.576   125  0.0228 Preprocessor1_Model3\n3          3 accuracy binary     0.544   125  0.0205 Preprocessor1_Model1\n4          2 accuracy binary     0.524   125  0.0226 Preprocessor1_Model2\n\n\nLet’s select the best performing tree_depth value based on classification accuracy.\n\nhighest_accuracy &lt;- select_best(search_grid, metric = \"accuracy\")\nhighest_accuracy\n\n# A tibble: 1 × 2\n  tree_depth .config             \n       &lt;int&gt; &lt;chr&gt;               \n1          1 Preprocessor1_Model4\n\n\nYou can now finalize workflow with the best performing hyperparameter value and estimate a model by using entire training data.\n\ntree_fit &lt;- \n  tree_wflow |&gt; \n  finalize_workflow(highest_accuracy) |&gt; \n  fit(df_train)\n\ntree_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nclass ~ x1 + x2\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 10 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 10 5 1 (0.5000000 0.5000000)  \n  2) x2&gt;=5.5 3 0 1 (1.0000000 0.0000000) *\n  3) x2&lt; 5.5 7 2 2 (0.2857143 0.7142857) *\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you pass control = control_grid(save_workflow = TRUE) in tune_grid() call, you can use fit_best() as a shortcut for steps of select_best(), finalize_workflow() and fit(). Please see an example here.\n\n\nLet’s make a prediction on test data.\n\nresults &lt;-\n  df_test |&gt; \n  bind_cols(\n    predict(tree_fit, df_test)\n  )\n\nresults\n\n# A tibble: 6 × 4\n     x1    x2 class .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;      \n1     1     5 1     2          \n2     0     5 1     2          \n3     3     4 2     2          \n4     4     3 2     2          \n5     2     7 1     1          \n6     1     4 2     2          \n\n\n\naccuracy(results, truth = class, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.667",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Decision tree</span>"
    ]
  },
  {
    "objectID": "ch09_svm.html",
    "href": "ch09_svm.html",
    "title": "9  Support vector machine",
    "section": "",
    "text": "9.1 Example 9.2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Support vector machine</span>"
    ]
  },
  {
    "objectID": "ch09_svm.html#example-9.2",
    "href": "ch09_svm.html#example-9.2",
    "title": "9  Support vector machine",
    "section": "",
    "text": "9.1.1 Load data\n\ndat &lt;- read_csv(\"data/ch9_dat2.csv\") |&gt; \n  mutate(class = as.factor(class))\n\nRows: 10 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x1, x2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat\n\n# A tibble: 10 × 3\n      x1    x2 class\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n 1     5     7 1    \n 2     4     3 -1   \n 3     7     8 1    \n 4     8     6 1    \n 5     3     6 -1   \n 6     2     5 -1   \n 7     6     6 1    \n 8     9     6 1    \n 9     5     4 -1   \n10     7     6 -1   \n\n\n\n\n9.1.2 Create a workflow for linear support vector machine\nCreate a linear support vector machine (SVM) modeling workflow. Use svm_linear() to define a model; it uses {LiblineaR} as default engine, but let us use {kernlab} in this example. Set mode to be \"classification\" and cost as a placeholder to be optimized based on cross validation.\n\nsvm_rec &lt;- recipe(class ~ x1 + x2, data = dat)\n\nsvm_model &lt;- \n  svm_linear(cost = tune()) |&gt; \n  set_engine(\"kernlab\", scaled = FALSE) |&gt;\n  set_mode(\"classification\")\n\nsvm_wflow &lt;-\n  workflow() |&gt; \n  add_recipe(svm_rec) |&gt; \n  add_model(svm_model)\n\n\n\n9.1.3 Hyperparameter optimization\nLet change cost parameter space be between 1 (i.e. 10^0) and 100 (i.e. 10^2).\n\nsvm_set &lt;- extract_parameter_set_dials(svm_wflow)\nsvm_set &lt;-\n  svm_set |&gt; \n  update(cost = cost(range = c(0, 2), trans = transform_log10()))\n\nRepeat 5-fold cross validation 10 times to evaluate performance of each cost value. Let’s use 15 different values of cost. This may take a minute. Please note that control = control_grid(save_workflow = TRUE) is passed to make model fitting more convenient in next steps.\n\nset.seed(58945)\n\nfolds &lt;- vfold_cv(dat, v = 5, repeats = 10, strata = class)\n\nsvm_search_grid &lt;-\n  svm_wflow |&gt; \n  tune_grid(\n    resamples = folds,\n    param_info = svm_set,\n    grid = 15,\n    control = control_grid(save_workflow = TRUE)\n  )\n\nVisualize the cross validation results.\n\nautoplot(svm_search_grid)\n\n\n\n\n\n\n\n\nFit a model with parameter value associated with highest classification accuracy.\n\nsvm_fit &lt;- fit_best(svm_search_grid, metric = \"accuracy\")\n\n Setting default kernel parameters  \n\nsvm_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: svm_linear()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 1.22532158146105 \n\nLinear (vanilla) kernel function. \n\nNumber of Support Vectors : 4 \n\nObjective Function Value : -3.6808 \nTraining error : 0.1 \nProbability model included. \n\n\n\n\n9.1.4 Visualize a model\n\nsvm_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  extract_fit_engine() |&gt; \n  plot(data = dat)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Support vector machine</span>"
    ]
  },
  {
    "objectID": "ch09_svm.html#example-9.7",
    "href": "ch09_svm.html#example-9.7",
    "title": "9  Support vector machine",
    "section": "9.2 Example 9.7",
    "text": "9.2 Example 9.7\n\n9.2.1 Load data\n\ndat &lt;- read_csv(\"data/ch9_dat3.csv\") |&gt; \n  mutate(class = as.factor(class))\n\nRows: 9 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x1, x2, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat\n\n# A tibble: 9 × 3\n     x1    x2 class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n1     5     7 1    \n2     4     3 -1   \n3     7     8 -1   \n4     8     6 -1   \n5     3     6 1    \n6     2     5 1    \n7     6     6 1    \n8     9     6 -1   \n9     5     4 -1   \n\n\n\n\n9.2.2 Define a workflow for polynomial SVM\nR code is almost identical to linear SVM workflow, except using svm_poly() instead of svm_linear() in model definition and setting degree parameter for polynomial degree. {kernlab} is a default engine for svm_poly().\n\nsvm_rec &lt;- recipe(class ~ x1 + x2, data = dat)\n\nsvm_model &lt;- \n  svm_poly(cost = tune(), degree = 2) |&gt; \n  set_engine(\"kernlab\", scaled = FALSE) |&gt;\n  set_mode(\"classification\")\n\nsvm_wflow &lt;-\n  workflow() |&gt; \n  add_recipe(svm_rec) |&gt; \n  add_model(svm_model)\n\n\n\n9.2.3 Hyperparameter optimization\nTake the same approach to the previous example.\n\nsvm_set &lt;- extract_parameter_set_dials(svm_wflow)\nsvm_set &lt;-\n  svm_set |&gt; \n  update(cost = cost(range = c(0, 2), trans = transform_log10()))\n\nset.seed(90851)\n\nfolds &lt;- vfold_cv(dat, v = 5, repeats = 10, strata = class)\n\nsvm_search_grid &lt;-\n  svm_wflow |&gt; \n  tune_grid(\n    resamples = folds,\n    param_info = svm_set,\n    grid = 15,\n    control = control_grid(save_workflow = TRUE)\n  )\n\n→ A | warning: No control observations were detected in `truth` with control level '1'.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x2\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x4\n\n\nThere were issues with some computations   A: x5\n\n\nThere were issues with some computations   A: x6\n\n\nThere were issues with some computations   A: x7\n\n\nThere were issues with some computations   A: x8\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\nThere were issues with some computations   A: x10\n\n\n\n\nautoplot(svm_search_grid)\n\n\n\n\n\n\n\nsvm_fit &lt;- fit_best(svm_search_grid, metric = \"accuracy\")\nsvm_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: svm_poly()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 1.85777218447856 \n\nPolynomial kernel function. \n Hyperparameters : degree =  2  scale =  1  offset =  1 \n\nNumber of Support Vectors : 6 \n\nObjective Function Value : -3.3638 \nTraining error : 0.111111 \nProbability model included. \n\n\n\n\n9.2.4 Visualize a model\n\nsvm_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  extract_fit_engine() |&gt; \n  plot(data = dat)\n\n\n\n\n\n\n\n\n\n\n9.2.5 Prediction\nMake a prediction by calling predict().\n\nresults &lt;- dat |&gt; \n  bind_cols(\n    predict(svm_fit, dat)\n  )\n\nresults\n\n# A tibble: 9 × 4\n     x1    x2 class .pred_class\n  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;      \n1     5     7 1     1          \n2     4     3 -1    -1         \n3     7     8 -1    -1         \n4     8     6 -1    -1         \n5     3     6 1     1          \n6     2     5 1     1          \n7     6     6 1     -1         \n8     9     6 -1    -1         \n9     5     4 -1    -1         \n\n\nFind misclassified observations. Used add_rowindex() to have row number in new column .row to clarify which row in the data have misclassified cases.\n\nresults |&gt; \n  add_rowindex() |&gt; \n  filter(class != .pred_class)\n\n# A tibble: 1 × 5\n     x1    x2 class .pred_class  .row\n  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;\n1     6     6 1     -1              7",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Support vector machine</span>"
    ]
  },
  {
    "objectID": "ch09_svm.html#example-9.8",
    "href": "ch09_svm.html#example-9.8",
    "title": "9  Support vector machine",
    "section": "9.3 Example 9.8",
    "text": "9.3 Example 9.8\n\n9.3.1 Load data\nClass label 2 means benign, while 4 means malignant. Let us 4 be the first class in class levels.\nOriginal data include several rows that contain missing values. Remove them before analysis.\n\ndat &lt;- read_csv(\"data/breast-cancer-wisconsin.csv\") |&gt; \n  mutate(class = factor(class, levels = c(4, 2))) |&gt; \n  drop_na()\n\nRows: 699 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, class\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n9.3.2 Train/Test data split\nSplit data into training and testing data sets in 2:1 ratio. Column X1 represents sample code number, and some samples appear multiple times in the data. To avoid data leakage, use group_initial_split() with group = X1 argument to split data by a set of sample code.\n\nset.seed(578925)\ndat_split &lt;- group_initial_split(dat, group = X1, prop = 2 / 3)\ntraining_dat &lt;- training(dat_split)\ntesting_dat &lt;- testing(dat_split)\n\n\n\n9.3.3 Define a workflow for nonlinear SVM with radius basis function (RBF) kernel\nDefine a recipe with model formula. Exclude X1 from predictors.\n\nsvm_rec &lt;- \n  recipe(class ~ ., data = training_dat) |&gt; \n  step_rm(X1)\n\nUse svm_rbf() to define a SVM model with radius basis function (RBF) kernel. This kernel function takes a hyperparameter rbf_sigma. Let us make it as a placeholder as well as cost, so both hyperparameters are optimized through cross-validation process. The default engine for svm_rbf() is {kernlab}.\n\nsvm_model &lt;-\n  svm_rbf(cost = tune(), rbf_sigma = tune()) |&gt;\n  set_engine(\"kernlab\") |&gt; \n  set_mode(\"classification\")\n\nDefine a workflow.\n\nsvm_wflow &lt;-\n  workflow() |&gt; \n  add_recipe(svm_rec) |&gt; \n  add_model(svm_model)\n\n\n\n9.3.4 Hyperparameter optimization\nSee there are two hyperparameters to be tuned. Let us rely on the default parameter value spaces in this example.\n\nsvm_set &lt;- extract_parameter_set_dials(svm_wflow)\nsvm_set\n\nCollection of 2 parameters for tuning\n\n identifier      type    object\n       cost      cost nparam[+]\n  rbf_sigma rbf_sigma nparam[+]\n\n\nConstruct data split for 10-fold cross-validation. Let us do not repeat the cross-validation in this example. As did in initial training/testing split, create folds by sample code number X1 by calling group_vfold_cv().\n\nset.seed(249085)\n\nfolds &lt;- group_vfold_cv(dat, group = X1, v = 10)\n\nCall tune_bayes() to tune hyperparameters by Bayesian optimization. Set metrics = metric_set(accuracy) to optimize hyperparameters based on classification accuracy. For more details, please see tidymodels website.\n\nsvm_search_bayes &lt;-\n  svm_wflow |&gt; \n  tune_bayes(\n    resamples = folds,\n    initial = 10,\n    iter = 20,\n    metrics = metric_set(accuracy),\n    control = control_bayes(no_improve = 10, save_workflow = TRUE)\n  )\n\n! No improvement for 10 iterations; returning current results.\n\n\nFew best performing hyperparameters are as follows:\n\nshow_best(svm_search_bayes)\n\nWarning in show_best(svm_search_bayes): No value of `metric` was given;\n\"accuracy\" will be used.\n\n\n# A tibble: 5 × 9\n    cost rbf_sigma .metric  .estimator  mean     n std_err .config         .iter\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;\n1  5.75   0.0305   accuracy binary     0.972    10 0.00575 Iter3               3\n2 26.4    0.000212 accuracy binary     0.970    10 0.00597 Iter8               8\n3  1.55   0.0353   accuracy binary     0.970    10 0.00599 Iter6               6\n4  0.374  0.0418   accuracy binary     0.970    10 0.00642 Preprocessor1_…     0\n5  0.520  0.0620   accuracy binary     0.970    10 0.00642 Iter12             12\n\n\nFinal model:\n\nsvm_fit &lt;- fit_best(svm_search_bayes)\nsvm_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: svm_rbf()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSupport Vector Machine object of class \"ksvm\" \n\nSV type: C-svc  (classification) \n parameter : cost C = 5.75272089604549 \n\nGaussian Radial Basis kernel function. \n Hyperparameter : sigma =  0.030522102456697 \n\nNumber of Support Vectors : 61 \n\nObjective Function Value : -244.7999 \nTraining error : 0.02489 \nProbability model included. \n\n\n\n\n9.3.5 Prediction\nCall predict() to make a prediction.\n\nresults &lt;- \n  testing_dat |&gt; \n  bind_cols(\n    predict(svm_fit, new_data = testing_dat)\n  )\n\nresults\n\n# A tibble: 228 × 12\n        X1    X2    X3    X4    X5    X6    X7    X8    X9   X10 class\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n 1 1000025     5     1     1     1     2     1     3     1     1 2    \n 2 1002945     5     4     4     5     7    10     3     2     1 2    \n 3 1015425     3     1     1     1     2     2     3     1     1 2    \n 4 1016277     6     8     8     1     3     4     3     7     1 2    \n 5 1017023     4     1     1     3     2     1     3     1     1 2    \n 6 1018561     2     1     2     1     2     1     3     1     1 2    \n 7 1035283     1     1     1     1     1     1     3     1     1 2    \n 8 1036172     2     1     1     1     2     1     2     1     1 2    \n 9 1041801     5     3     3     3     2     3     4     4     1 4    \n10 1050718     6     1     1     1     2     1     3     1     1 2    \n# ℹ 218 more rows\n# ℹ 1 more variable: .pred_class &lt;fct&gt;\n\n\nSee confusion matrix.\n\nconf_mat(results, truth = class, estimate = .pred_class)\n\n          Truth\nPrediction   4   2\n         4  70   6\n         2   3 149\n\n\nSee classification accuracy, F1-score, and some other metrics.\n\nmulti_metrics &lt;- metric_set(accuracy, f_meas, precision, recall)\nmulti_metrics(results, truth = class, estimate = .pred_class)\n\n# A tibble: 4 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.961\n2 f_meas    binary         0.940\n3 precision binary         0.921\n4 recall    binary         0.959",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Support vector machine</span>"
    ]
  }
]